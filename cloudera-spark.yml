application:
  configuration:
    input.identity: "root"
    input.cookbooks_url: "https://s3.amazonaws.com/qubell-starter-kit-artifacts/qubell-bazaar/component-hadoop-cookbooks-stable-v5.tar.gz"
    input.repository_url: "http://arcspark.cloudera.com"
    input.cloudera_manager_version: "5.1.3"
    input.cloudera_hadoop_version: "5.1.3"
  interfaces:
    input:
      identity: "bind(cloudera-spark#input.identity)"
      cookbooks_url: "bind(cloudera-spark#input.cookbooks_url)"
      repository_url: "bind(cloudera-spark#input.repository_url)"
      cloudera_manager_version: "bind(cloudera-spark#input.cloudera_manager_version)"
      cloudera_hadoop_version: "bind(cloudera-spark#input.cloudera_hadoop_version)"
    vms:
      Node_Manager: "bind(cloudera-spark#vms.Node_Manager)"
      Node_Manager_DNS: "bind(cloudera-spark#vms.Node_Manager_DNS)"
      Node_Master: "bind(cloudera-spark#vms.Node_Master)"
      Node_Master_DNS: "bind(cloudera-spark#vms.Node_Master_DNS)"
      DataNodes: "bind(cloudera-spark#vms.DataNodes)"
      DataNodesDNS: "bind(cloudera-spark#vms.DataNodesDNS)"
    cloudera-yarn:
      Resource_Manager_Uri: "bind(cloudera-spark#cloudera-yarn.Resource_Manager_Uri)"
      Job_History_Uri: "bind(cloudera-spark#cloudera-yarn.Job_History_Uri)"
    cloudera-spark:
      Spark_History_Uri: "bind(cloudera-spark#result.Spark_History_Uri)"
      application-pic: "bind(metadata#output.application-pic)"
  components:
    metadata:
      type: cobalt.common.Constants
      interfaces:
        output:
          application-pic:
            type: publish-signal(map<string, object>)
            name: ""
      configuration:
        configuration.values:
          output.application-pic:
            large: "https://s3.amazonaws.com/qubell-images/spark.png"
            small: "https://s3.amazonaws.com/qubell-images/spark.png"
            small-height: 90
    cloudera-spark:
      type: workflow.Instance
      interfaces:
        input:
          identity:
            type: configuration(string)
            name: EC2 image username
          repository_url:
            type: configuration(string)
            name: Cloudera RPM repository
          cookbooks_url:
            type: configuration(string)
            name: Chef cookbooks
          cloudera_hadoop_version:
            type: configuration(string)
            name: Cloudera Hadoop version
          cloudera_manager_version:
            type: configuration(string)
            name: Cloudera Manager version
        vms:
          Node_Manager: consume-signal(list<string>)
          Node_Manager_DNS: consume-signal(string)
          Node_Master: consume-signal(list<string>)
          Node_Master_DNS: consume-signal(string)
          DataNodes: consume-signal(list<string>)
          DataNodesDNS: consume-signal(list<string>)
        cloudera-yarn:
          Resource_Manager_Uri: consume-signal(string)
          Job_History_Uri: consume-signal(string)
        result:
          Spark_History_Uri:
            type: publish-signal(string)
            name: Spark History Server
      required: [vms, cloudera-yarn]
      configuration:
        configuration.triggers: {}
        configuration.workflows:
          launch:
            steps:
              - get-env-props:
                  action: getEnvironmentProperties
                  output:
                    props: result
              - provision-master-node:
                  action: provisionVms
                  precedingPhases: [ get-env-props ]
                  parameters:
                    roleName: "master"
                    hardwareId: ""
                    vmIdentity: "{$.identity}"
                    staticIps: "{$.props.vms.Node_Master}"
                  output:
                    masterIp: ips
              - install-spark-pkg:
                  action: chefrun
                  precedingPhases: [ provision-master-node ]
                  parameters:
                    isSudo: true
                    isSolo: true
                    roles: [ "master" ]
                    recipeUrl: "{$.cookbooks_url}"
                    runList: [ "recipe[cloudera::spark_pkg]" ]
                    retryCount: 2
                    jattrs:
                      java:
                        java_home: "/usr/java/jdk6"
                      cloudera:
                        hadoop:
                          version: "{$.cloudera_hadoop_version}"
                        manager:
                          version: "{$.cloudera_manager_version}"
                        repository_url: "{$.repository_url}"
              - add-spark-on-yarn:
                  action: chefrun
                  phase: add-spark-on-yarn
                  precedingPhases: [ install-spark-pkg ]
                  parameters:
                    isSudo: true
                    isSolo: true
                    roles: [ "master" ]
                    recipeUrl: "{$.cookbooks_url}"
                    runList: [ "recipe[cloudera::spark]" ]
                    jattrs:
                      java:
                        java_home: "/usr/java/jdk6"
                      cloudera:
                        master:
                          host: "{$.props.vms.Node_Master_DNS}"
                        manager:
                          host: "{$.props.vms.Node_Manager_DNS}"
                          version: "{$.cloudera_manager_version}"
                        datanodes:
                          hosts: "{$.props.vms.*.DataNodesDNS}"
                        hadoop:
                          version: "{$.cloudera_hadoop_version}"
                        repository_url: "{$.repository_url}"
            return:
              - Spark_History_Uri:
                  description: "Job History server url"
                  value: "http://{$.props.vms.Node_Master_DNS}:18088"
